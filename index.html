<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Skylark Space</title><meta name="author" content="Ryan Wong"><meta name="copyright" content="Ryan Wong"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Skylark Space">
<meta property="og:url" content="http://ryan-nightwish.github.io/index.html">
<meta property="og:site_name" content="Skylark Space">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://ryan-nightwish.github.io/img/avatar.png">
<meta property="article:author" content="Ryan Wong">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://ryan-nightwish.github.io/img/avatar.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://ryan-nightwish.github.io/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Skylark Space',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-08-02 17:08:58'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/styles.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/static-butterfly/dist/css/index.min.css"><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/top_img.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Skylark Space"><span class="site-name">Skylark Space</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Skylark Space</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/Ryan-Nightwish" target="_blank" title="Github"><i class="fab fa-github" style="color: #hdhfbb;"></i></a><a class="social-icon" href="mailto:718102754@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #000000;"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/08/02/GAN%E7%B3%BB%E5%88%97%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/" title="GAN系列经典算法整理">GAN系列经典算法整理</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-08-02T02:21:35.000Z" title="发表于 2023-08-02 10:21:35">2023-08-02</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-02T09:03:31.919Z" title="更新于 2023-08-02 17:03:31">2023-08-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%95%B4%E5%90%88%E7%AC%94%E8%AE%B0/">整合笔记</a></span></div><div class="content">GAN系列经典算法整理

整理思路参考：GAN系列算法原理及极简代码解析

经典GAN
见博客：GAN论文阅读笔记
DCGAN

原文：Unsupervised
Representation Learning with Deep Convolutional Generative Adversarial
Networks
出处：ICLR 2016
引用：15458
参考：【生成对抗网络】Deep
Convolution GAN (DCGAN) 详细解读

DCGAN的全称是Deep Convolution Generative Adversarial
Networks，即深度卷积生成对抗网络。简单概括，这个模型在Original
GAN的理论基础上，将CNN和GAN结合实现对图像的处理，并提出了一系列对网络结构的限制，以提高网络的稳定性。
DCGAN对现有的GAN架构做了如下几个方面的修改： -
全卷积网络：用步幅卷积替代确定性空间池化函数（如最大池化），让网络自己学习下采样方式。作者对生成器和辨别器都采用了这种方法。
-
取消全连接层：比如使用全局平均池化代替全连接层。全局平均池化会降 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/07/24/RoBERTa%E7%9A%84%E5%8F%98%E5%8C%96/" title="RoBERTa的变化">RoBERTa的变化</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-24T07:59:23.000Z" title="发表于 2023-07-24 15:59:23">2023-07-24</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-24T08:13:09.963Z" title="更新于 2023-07-24 16:13:09">2023-07-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">RoBERTa的变化

原文：RoBERTa: A
Robustly Optimized BERT Pretraining Approach
年份：2019
引用：7874
参考：RoBERTa -
论文解读，Roberta的原理介绍


:star:
它在模型层面没有改变Google的Bert，改变的只是预训练的方法。

更大的mini-batch
原本的BERT-base的batch size是256，训练了1M个steps。而RoBERTa的batch
size是8k，训练31K个steps。
为什么使用更大的batch size：

有钱
在机器翻译中，用更大的batch
size配合更大学习率能提升模型优化速率和模型性能（Past work in Neural
Machine Translation has shown that training with very large mini-batches
can both improve optimization speed and end-task performance when the
learning rate is  ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/06/26/GAN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="GAN论文阅读笔记">GAN论文阅读笔记</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-26T02:15:52.000Z" title="发表于 2023-06-26 10:15:52">2023-06-26</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-27T01:43:28.631Z" title="更新于 2023-07-27 09:43:28">2023-07-27</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">GAN论文阅读笔记

出处：arXiv 2014
原文：https://arxiv.org/pdf/1406.2661.pdf
代码：adversarial
参考：GAN论文逐段精读【论文精读】

摘要
本文提出了一种通过对抗过程来评估生成模型的框架，需要同时训练两个模型：

G，即生成模型，用于生成数据分布
D，即分辨模型，用于判断数据是现有的训练数据还是G生成的数据

其中，G的训练过程是为了增大D的犯错概率（虽然一般来说生成模型是让数据分布尽可能靠近），所以我们可以把这个框架比作一个“minmax
two-player
game”。在G和D的函数空间中，存在一组解，使得G可以完全覆盖训练数据并且D在任何地方都等于。因为G和D都是MLP，所以整个系统可以通过反向传播来进行更新训练，而不需要任何马尔可夫链或展开近似推理网络。

Chat老师：
在博弈论中，Minimax是一种用于决策和游戏理论中寻找玩家最优策略的回溯算法。在Minimax中，两个玩家被称为最大化者（maximizer）和最小化者（minimizer）。最大化者试图获得尽可能高的分数，而最小化者则相反，试图获得尽可能低 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/06/21/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="知识蒸馏论文笔记">知识蒸馏论文笔记</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-21T02:16:01.000Z" title="发表于 2023-06-21 10:16:01">2023-06-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-27T02:56:59.316Z" title="更新于 2023-06-27 10:56:59">2023-06-27</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">知识蒸馏论文笔记

出处：NIPS 2015
原文：Distilling the
Knowledge in a Neural Network
阅读参考：知识蒸馏：从神经网络中蒸馏知识
Distilling the Knowledge in a Neural Network、论文 -
Distilling the Knowledge in a Neural Network、Distilling the
Knowledge in a Neural Network
实验代码：distillation from
labmi

摘要

提高机器学习算法性能的一个简单方法是在相同数据上训练许多不同的模型，然后对其预测进行平均化。然而，这个方法的计算成本太高，特别是当单个模型就是大型神经网络。
Caruana曾表示，如果可以将集合的知识压缩到一个单一的模型中，那么这样将更容易部署。
我们使用不同的压缩技术对这种思想进行了进一步的发展，通过将模型集合中的知识提炼成一个单一的模型，在MNIST上取得了惊人的结果。另外，我们还提出了一种由一个或多个完整模型和许多专家模型组成的新型集合体，这些模型学会了区分 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/06/19/LocalMIM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="LocalMIM论文阅读笔记">LocalMIM论文阅读笔记</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-19T02:32:16.000Z" title="发表于 2023-06-19 10:32:16">2023-06-19</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-21T10:13:32.988Z" title="更新于 2023-06-21 18:13:32">2023-06-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">LocalMIM论文阅读笔记

出处：CVPR 2023
原文：Masked Image
Modeling with Local Multi-Scale Reconstruction
代码：LocalMIM
中文参考：【CVPR2023】Masked Image
Modeling with Local Multi-Scale Reconstruction

摘要

一般的MIM模型都有巨大的计算负担和缓慢的学习过程，而这在生产过程中是不可避免的障碍。
尽管低层在MIM中起着关键作用，但现有的MIM模型只在编码器的顶层进行重建工作。更低的层并没有受到明确的指导，它们之间的交互只是用于计算新的激活值。

Chat老师：在MIM中，较低层的网络通常负责提取图像的局部特征，这些特征对于重构任务非常重要。然而，现有的MIM模型只在编码器的顶层进行重构任务，这意味着较低层没有被要求进行重构任务，它们的主要任务是计算新的激活值以供上层网络使用。

鉴于重构任务需要进行复杂的patch间相互作用来推理目标信号，我们设计了局部多尺度的重建，其中下层和上层分别重建细尺度和粗尺度的监督信号。这个设计不仅可以 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/06/18/MAE%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="MAE论文阅读笔记">MAE论文阅读笔记</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-18T10:24:09.000Z" title="发表于 2023-06-18 18:24:09">2023-06-18</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-18T10:34:57.377Z" title="更新于 2023-06-18 18:34:57">2023-06-18</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">MAE论文阅读笔记

原作LH，搬运，已同意
代码链接: https://github.com/facebookresearch/mae
会议/期刊分区: CVPR
年份: 2022
论文链接:
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9879206

1. 标题
Masked Autoencoder Are Scalable Vision Learners

Scalable：可拓展的
Vision
Learner：这里没有写成classifier或者其他的东西，因为它能够用到的地方相对广一些，他是一个backbone模型
💡
backbone通常指神经网络模型的主干部分，也就是提取特征的部分
Masked：masked来源于BERT，每次挖掉一些东西然后去预测被挖掉的东西
Autoencoder：这里的auto不是自动的意思，而是“自”的意思，标号和样本（y和x）来自于同一个东西。在NLP中，大家都是可以理解的，但是在计算机视觉中，图片的标号很少来自图片本身，所以作者在这里加上了auto，意在指出和 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/06/15/%E6%9C%8D%E5%8A%A1%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E7%82%B9/" title="服务开发技术知识点">服务开发技术知识点</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-15T01:47:23.000Z" title="发表于 2023-06-15 09:47:23">2023-06-15</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-15T02:31:29.663Z" title="更新于 2023-06-15 10:31:29">2023-06-15</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a></span></div><div class="content">服务开发技术知识点
第二章 从RPC到REST
探寻Web运行的终极原理
1、Web技术框架的四个基石：

URI：地址
HTTP：传输
HyperText：表达
MIME：拓展

2、任何寄宿于Web服务器可以利用HTTP协议获取或者操作的“事物”均可以称为资源。
3、Web资源应该有一个唯一的标识，采用URI来标识。URL是“统一资源定位符”，是URI的一种表现形式。URN也是URI的表现形式，“统一资源名称”。
4、CRUD模式：CREATE-READ-UPDATE-DELETE
5、客户端和Web服务器在一次HTTP事务中交换的消息被称为HTTP报头，客户端发送给服务器的请求消息被称为请求报文，服务器返回给客户端的响应消息被称为响应报头。
6、一个完整的HTTP报文由三个部分组成：

起始行：HTTP方法、请求URI、HTTP版本、响应码
报头集合：键值对，冒号分割
主体内容：数据

7、HTTP请求的三个基本属性：

HTTP方法
目标资源
协议版本

8、REST的宗旨是从资源的角度来观察整个网络，分布在各处的资源由URI确定，而客户端的应用通过URI来获取资源的表征，获得 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/06/15/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="软件测试复习笔记">软件测试复习笔记</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-15T01:47:23.000Z" title="发表于 2023-06-15 09:47:23">2023-06-15</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-15T02:23:57.076Z" title="更新于 2023-06-15 10:23:57">2023-06-15</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a></span></div><div class="content">软件测试复习笔记
一、引论
为什么进行软件测试

产品质量的保证
控制成本的关键
软件可靠性确认
让企业具备国际竞争的实力

什么是软件测试
1、正向思维——验证软件正常工作：

软件测试就是为程序能够按预期设想那样运行而建立足够的信心
“软件测试是一系列活动以评价一个程序或系统的特性或能力并确定是否达到预期的结果”
测试是为了验证软件是否符合用户需求，即验证软件产品是否能正常工作

2、反向思维——假定软件有错误：

测试是为了证明程序有错，而不是证明程序无错误
一个好的测试用例是在于它能发现至今未发现的错误
一个成功的测试是发现了至今未发现的错误的测试


Chat老师：
在软件测试中，正向思维和逆向思维是两种测试方法，它们的主要区别在于测试的目的和方法。正向思维是指测试人员按照预期的功能和需求来测试软件，而逆向思维则是从不符合预期的情况出发，测试来发现软件中的缺陷和漏洞。
虽然正向思维和逆向思维在过去被广泛使用，但现在它已经不再流行的原因是因为它们存在一些缺陷和局限性。正向思维只能测试软件的预期功能而无法发现软件中的潜在问题和漏洞。逆向思维虽然可以发现软件中的缺陷和漏洞，但它往往 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/06/15/web%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E7%9F%A5%E8%AF%86%E7%82%B9/" title="web数据管理复习">web数据管理复习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-15T01:47:23.000Z" title="发表于 2023-06-15 09:47:23">2023-06-15</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-15T02:29:39.274Z" title="更新于 2023-06-15 10:29:39">2023-06-15</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a></span></div><div class="content">web数据管理复习
第一讲 绪论
web数据
1、web数据的特点：

数据量大，且仍在不断增长
存在各种类型的数据
异构的信息：内容相同，形式不同
绝大部分信息是相连接的图结构
存在噪音
动态性

web数据管理
1、Web数据管理的定义是：在Web环境下对复杂信息的有效组织与集成，方便而准确地获取信息。
web数据管理的内容

获取
数据组织
信息集成
查询
信息发布

web数据管理的基础

数据获得
数据预处理
数据变换
数据挖掘与机器学习
知识发现

第二讲 网络爬虫技术
爬虫定义
1、爬虫是一种自动获取网页内容的程序，是搜索引擎的重要组成部分。也就是通过HTML源码解析来获得想要的内容。
爬取过程

从一个或若干个初始网页URL开始
获取HTML源码文件
解析源码文件，寻找URL放入队列
从队列中取出URL继续

爬虫必须具有的功能

礼貌性：Web服务器有显式或隐式的策略控制爬虫的访问。隐式的礼貌指即使没有特别的说明，也不频繁访问同一个网站；显式的礼貌指根据站长说明，选择允许爬取的部分爬取，尊重robors.txt(对爬取过程进行限制)
鲁棒性：能从采集器陷阱中跳出，能处 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/05/30/ViT%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="ViT论文阅读笔记">ViT论文阅读笔记</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-30T13:42:37.000Z" title="发表于 2023-05-30 21:42:37">2023-05-30</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-19T02:37:52.010Z" title="更新于 2023-06-19 10:37:52">2023-06-19</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="content">ViT论文阅读笔记

出处：ICLR 2021
原文：An Image is Worth
16x16 Words: Transformers for Image Recognition at Scale
代码：vision_transformer

摘要
虽然Transformer架构已经成为自然语言处理领域标准的处理手段，但是它在计算机视觉的应用还是很有限的。在视觉任务中，注意力机制要么和CNN结合使用，要么用于替换CNN网络中的一些部件。我们将展示，这种对CNN的依赖不是必须的，直接应用于图片序列的纯Transformer在图像分类任务上也可以取得很好的效果。当对大量数据进行预训练并转移到多个中小型或小型图像识别基准时（如ImageNet、CIFAR-100、VTAB），ViT获得了与最先进的CNN相比更出色的效果，同时需要更少的计算资源来训练。
介绍
Transformer最主要的方法就是在大的文本数据集上进行预训练，然后在特定任务的小数据集上进行微调。由于其结构的计算效率和可拓展性，它可以训练前所未有的规模模型，可能超过100B的参数量。随着模型和数据集的增长，仍然没有饱和性能 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Ryan Wong</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Ryan-Nightwish" target="_blank" title="Github"><i class="fab fa-github" style="color: #hdhfbb;"></i></a><a class="social-icon" href="mailto:718102754@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #000000;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/02/GAN%E7%B3%BB%E5%88%97%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/" title="GAN系列经典算法整理">GAN系列经典算法整理</a><time datetime="2023-08-02T02:21:35.000Z" title="发表于 2023-08-02 10:21:35">2023-08-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/24/RoBERTa%E7%9A%84%E5%8F%98%E5%8C%96/" title="RoBERTa的变化">RoBERTa的变化</a><time datetime="2023-07-24T07:59:23.000Z" title="发表于 2023-07-24 15:59:23">2023-07-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/06/26/GAN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="GAN论文阅读笔记">GAN论文阅读笔记</a><time datetime="2023-06-26T02:15:52.000Z" title="发表于 2023-06-26 10:15:52">2023-06-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/06/21/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="知识蒸馏论文笔记">知识蒸馏论文笔记</a><time datetime="2023-06-21T02:16:01.000Z" title="发表于 2023-06-21 10:16:01">2023-06-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/06/19/LocalMIM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="LocalMIM论文阅读笔记">LocalMIM论文阅读笔记</a><time datetime="2023-06-19T02:32:16.000Z" title="发表于 2023-06-19 10:32:16">2023-06-19</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">深度学习</span><span class="card-category-list-count">11</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 1.5em; color: #99a9bf">论文阅读</a> <a href="/tags/%E6%95%B4%E5%90%88%E7%AC%94%E8%AE%B0/" style="font-size: 1.1em; color: #999">整合笔记</a> <a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 1.1em; color: #999">笔记</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 1.23em; color: #999ea6">机器学习</a> <a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 1.1em; color: #999">论文</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/" style="font-size: 1.37em; color: #99a4b2">课程笔记</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/08/"><span class="card-archive-list-date">八月 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/07/"><span class="card-archive-list-date">七月 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">六月 2023</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/05/"><span class="card-archive-list-date">五月 2023</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/04/"><span class="card-archive-list-date">四月 2023</span><span class="card-archive-list-count">5</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">18</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2023-08-02T09:08:58.474Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Ryan Wong</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>